{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from online.Environment import BatteryScheduling\n",
    "from online.EnergyDataset import EnergyDataset\n",
    "from torchrl.envs.utils import check_env_specs\n",
    "from hydra import initialize, compose\n",
    "from torchrl.modules import MLP, Actor,OrnsteinUhlenbeckProcessModule\n",
    "import torch\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    "    Compose,\n",
    "    InitTracker,\n",
    ")\n",
    "\n",
    "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "\n",
    "from torchrl.objectives import ValueEstimators, SoftUpdate, DDPGLoss\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyMemmapStorage, ReplayBuffer, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = EnergyDataset('../data/1_processed/energy.csv', '../data/1_processed/price.csv', 10, 1, 'train')\n",
    "ds_test = EnergyDataset('../data/1_processed/energy.csv', '../data/1_processed/price.csv', 10, 1, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeEnv(cfg, seed, ds):\n",
    "    env = BatteryScheduling(cfg, 42, ds)\n",
    "    env_transformed = TransformedEnv(env, \n",
    "                                     Compose(InitTracker(),\n",
    "                                             UnsqueezeTransform(dim=-1, \n",
    "                                                                in_keys=['soe', 'prosumption', 'price', 'cost'],\n",
    "                                                                in_keys_inv=['soe', 'prosumption', 'price', 'cost'],),\n",
    "                                            CatTensors(dim=-1,\n",
    "                                                        in_keys=['time_feature', 'soe', 'prosumption', 'prosumption_forecast', 'price', 'price_forecast'],\n",
    "                                                        out_key='observation',\n",
    "                                                        del_keys=False),\n",
    "                                     )\n",
    "                                    )\n",
    "    return env_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510d4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"conf/\"):\n",
    "    cfg = compose(config_name='config.yaml')\n",
    "    env_train = makeEnv(cfg, 42, ds_train)\n",
    "  \n",
    "    # check_env_specs(env_train)\n",
    "\n",
    "\n",
    "    policy_net = MLP(\n",
    "        in_features=env_train.observation_spec['observation'].shape[-1],\n",
    "        out_features=env_train.action_spec.shape.numel(),\n",
    "        depth=2,\n",
    "        num_cells=[400,300],\n",
    "        activation_class=torch.nn.ReLU,\n",
    "    )\n",
    "\n",
    "    policy_module = TensorDictModule(\n",
    "        module=policy_net,\n",
    "        in_keys=['observation'],\n",
    "        out_keys=['action']\n",
    "    )\n",
    "\n",
    "    actor = Actor(\n",
    "        module=policy_module,\n",
    "        spec=env_train.full_action_spec['action'],\n",
    "        in_keys=['observation'],\n",
    "        out_keys=['action'],\n",
    "    )\n",
    "\n",
    "\n",
    "    ou = OrnsteinUhlenbeckProcessModule(\n",
    "        annealing_num_steps=25_000,\n",
    "        n_steps_annealing=25_000,\n",
    "        spec=actor.spec.clone(),\n",
    "    )\n",
    "\n",
    "    exploration_policy = TensorDictSequential(\n",
    "        actor,\n",
    "        ou\n",
    "    )\n",
    "\n",
    "\n",
    "    critic_module = TensorDictModule(\n",
    "        module=MLP(\n",
    "            in_features=env_train.observation_spec['observation'].shape[-1] + env_train.full_action_spec['action'].shape.numel(),\n",
    "            out_features=1,\n",
    "            depth=2,\n",
    "            num_cells=[400,300],\n",
    "            activation_class=torch.nn.ReLU,\n",
    "        ),\n",
    "        in_keys=['observation', 'action'],\n",
    "        out_keys=['state_action_value']\n",
    "    )\n",
    "\n",
    "    collector = SyncDataCollector(create_env_fn=makeEnv(cfg, 42, ds_train),\n",
    "                                  policy=exploration_policy,\n",
    "                                  frames_per_batch=100,\n",
    "                                  total_frames=100_000,)\n",
    "    \n",
    "    replay_buffer = ReplayBuffer(\n",
    "        storage=LazyMemmapStorage(\n",
    "            max_size=250_000,  # We will store up to memory_size transitions\n",
    "        ),  # We will store up to memory_size multi-agent transitions\n",
    "        sampler=RandomSampler(),\n",
    "        batch_size=32,  # We will sample batches of this size\n",
    "    )\n",
    "\n",
    "    loss_module = DDPGLoss(\n",
    "        actor_network=actor,\n",
    "        value_network=critic_module,\n",
    "        delay_value=True,\n",
    "    )\n",
    "\n",
    "    loss_module.make_value_estimator(ValueEstimators.TD0, gamma=0.99)\n",
    "\n",
    "    target_updater = SoftUpdate(loss_module,tau=0.001)\n",
    "\n",
    "    optimisers = {\n",
    "        \"loss_actor\": torch.optim.Adam(\n",
    "            loss_module.actor_network.parameters(), lr=1e-4\n",
    "        ),\n",
    "        \"loss_value\": torch.optim.Adam(\n",
    "            loss_module.value_network.parameters(), lr=1e-3\n",
    "        ),\n",
    "    }\n",
    "\n",
    "\n",
    "    for iteration, batch in enumerate(collector):\n",
    "        current_frames = batch.numel()\n",
    "        exploration_policy[-1].step(current_frames)\n",
    "        replay_buffer.extend(batch)\n",
    "\n",
    "        # Train for train_iterations_per_frame iterations per frame\n",
    "        for i in range(1):\n",
    "            sample = replay_buffer.sample()\n",
    "            loss_vals = loss_module(sample)\n",
    "            for loss_name in [\"loss_actor\", \"loss_value\"]:\n",
    "                loss = loss_vals[loss_name]\n",
    "                loss.backward()\n",
    "                optimiser = optimisers[loss_name]\n",
    "                optimiser.step()\n",
    "                optimiser.zero_grad()\n",
    "\n",
    "            # if (iteration*32+i) % 5 == 0:\n",
    "            target_updater.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7b8eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_test = makeEnv(cfg, 42, ds_test)\n",
    "env_test.reset()\n",
    "tensordict_result = env_test.rollout(max_steps=10000000, policy=actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ad24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensordict_result[-1]['next', 'cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dae7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tensordict_result[0:100]['soe'].detach().numpy()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tensordict_result[5700:5800]['action'].detach().numpy()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd5cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tensordict_result[5700:5800]['price'].detach().numpy()).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tensordict_result[5700:5800]['next', 'reward'].detach().numpy()).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision-transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
